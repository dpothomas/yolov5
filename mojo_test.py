# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license
"""
Validate a trained YOLOv5 model accuracy on a custom dataset

Usage:
    $ python path/to/val.py --data coco128.yaml --weights yolov5s.pt --img 640
"""

import argparse
import sys
from pathlib import Path

import cv2

import wandb

import numpy as np
import torch
from utils.general import xyxy2xywhn, scale_coords

FILE = Path(__file__).absolute()
sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path

from models.experimental import attempt_load
from utils.general import check_dataset, check_file, check_img_size, \
    non_max_suppression, set_logging, increment_path, colorstr
from utils.torch_utils import select_device
import val

from aisa_utils.dl_utils.utils import plot_object_count_difference_ridgeline, make_video_results


def get_images_and_labels(data):
    image_paths = list(Path(data).glob("*.jpg")) + list(Path(data).glob("*.png"))
    images = []
    labels = []
    for image_path in image_paths:
        image = cv2.imread(str(image_path), 0)
        images.append(image)
        label_path = image_path.parents[2] / "labels" / image_path.parent.stem / f"{image_path.stem}.txt"
        if label_path.is_file():
            label = []
            with label_path.open("r") as f:
                for line in f.readlines():
                    line = line.split()
                    line = [int(line[0])] + list(map(float, line[1:]))
                    label.append(line)
            labels.append(label)
        else:
            raise Exception(f"Missing label {label_path}")
    return images, labels


@torch.no_grad()
def mojo_test(data,
        weights=None,  # model.pt path(s)
        batch_size=32,  # batch size
        imgsz=640,  # inference size (pixels)
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        save_txt=False,  # save results to *.txt
        project='runs/val',  # save to project/name
        name='exp',  # save to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        entity=None,
        test_video_root=None
        ):

    device = select_device(device, batch_size=batch_size)
    print(f"data:{data}")
    data_dict = check_dataset(data)
    print(f"data_dict:{data_dict}")
    # Trainloader
    images, labels = get_images_and_labels(data_dict['test'])

    # Directories
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir
    # run_id = torch.load(weights[0]).get('wandb_id')

    # wandb_run = wandb.init(id=run_id,
    #                       project=project,
    #                       entity=entity,
    #                       resume='allow',
    #                       allow_val_change=True)

    results, maps, t, extra_metrics, _, _ = val.run(data,
        weights=weights,  # model.pt path(s)
        batch_size=batch_size,  # batch size
        imgsz=imgsz,  # inference size (pixels)
        conf_thres=0.001,  # confidence threshold
        iou_thres=0.6,  # NMS IoU threshold
        task='test',  # train, val, test, speed or study
        )
    total_inference_time = np.sum(t)
    print(f"total_inference_time={total_inference_time:.1f}ms")
    # wandb_run.log({f"mojo_test/test_metrics/mp": results[0]})
    # wandb_run.log({f"mojo_test/test_metrics/mr": results[1]})
    # wandb_run.log({f"mojo_test/test_metrics/map50": results[2]})
    # wandb_run.log({f"mojo_test/test_metrics/map": results[3]})
    # wandb_run.log({f"mojo_test/test_metrics/inference_time": total_inference_time})

    # Load model
    model = attempt_load(weights, map_location=device)  # load FP32 model
    gs = max(int(model.stride.max()), 32)  # grid size (max stride)
    imgsz = check_img_size(imgsz, s=gs)  # check image size

    # Half
    half = device.type != 'cpu'  # half precision only supported on CUDA
    if half:
        model.half()

    def video_prediction_function(frame_array, conf_thres=0.001):
        n_frames = len(frame_array)
        preds = []
        for i in range(0, n_frames, batch_size):
            frames = []
            for frame in frame_array[i: min(i + batch_size, n_frames)]:
                from utils.datasets import letterbox
                img = letterbox(frame, new_shape=(imgsz, imgsz))[0]
                img = np.array([img, img, img])
                img = np.ascontiguousarray(img)
                frames.append(img)
            frames = np.array(frames)

            # Convert img to torch
            img = torch.from_numpy(frames).to(device)
            img = img.half() if device.type != "cpu" else img.float()  # uint8 to fp16/32
            img /= 255.0  # 0 - 255 to 0.0 - 1.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)
            # Inference
            pred = model(img, augment=False)[0]
            # Apply NMS
            pred = non_max_suppression(pred, conf_thres=conf_thres)
            _ = []

            for j, det in enumerate(pred):
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], frame_array[i+j].shape)
                det = det.cpu().numpy()
                det[:, :4] = xyxy2xywhn(det[:, :4], w=frame_array[i+j].shape[1], h=frame_array[i+j].shape[0])
                _.append(det)
            preds += _
        return preds
    extra_plots = dict()
    preds = video_prediction_function(images)
    fig, suggested_threshold = plot_object_count_difference_ridgeline(labels, preds)
    extra_plots["object_count_difference"] = fig
    print(f"suggested_threshold={suggested_threshold}")
    # for plot_key in extra_plots:
    #     wandb_run.log({f"mojo_test/extra_plots/{plot_key}": extra_plots[plot_key]})
    #
    # if test_video_root:
    #     for video_path in Path(test_video_root).rglob("*.avi"):
    #         output_video_path, jitter_plot = make_video_results(video_path, lambda x: video_prediction_function(x, suggested_threshold))
    #
    #         wandb_run.log(
    #             {
    #                 f"mojo_test/extra_videos/{output_video_path.name}": wandb.Video(
    #                     str(output_video_path), fps=60, format="mp4"
    #                 )
    #             }
    #         )
    #         wandb_run.log({f"mojo_test/extra_plots/{output_video_path.name}_jitter": jitter_plot})

    return None


def parse_opt():
    parser = argparse.ArgumentParser(prog='mojo_test.py')
    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', nargs='+', type=str, default='yolov5s.pt', help='model.pt path(s)')
    parser.add_argument('--batch-size', type=int, default=32, help='batch size')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--project', default='runs/val', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--entity', default=None, help='W&B entity')
    opt = parser.parse_args()
    opt.data = opt.data  # check file
    return opt


def main(opt):
    set_logging()
    print(colorstr('mojo test: ') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))
    mojo_test(**vars(opt))


if __name__ == "__main__":
    #weights = Path(r"D:\Nanovare\dev\yolov5\wandb_mod_tests\exp\weights\best.pt")
    opt = parse_opt()
    main(opt)
